import os
from dotenv import load_dotenv
from langchain_core.output_parsers import StrOutputParser
from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace
from smolagents import HfApiModel, ToolCallingAgent

from galapassistant.apps.assistant.services.retriever_service import RetrieverTool


load_dotenv()

LLM_MODEL_NAME = "HuggingFaceH4/zephyr-7b-beta" ##Other models: "MaziyarPanahi/calme-3.1-instruct-78b", "meta-llama/Llama-3.1-70B-Instruct"

class AssistantLLMService:
    """
    Service class for generating responses using an LLM.
    """
    def __init__(self):
        """
        Initializes the AssistantLLMService by creating an instance of the LLM.
        """
        self.llm = HfApiModel(
            model_id=LLM_MODEL_NAME,
            token=os.getenv("HUGGINGFACEHUB_API_TOKEN"),
            temperature=0.3,
            max_tokens=256
        )

    def generate_answer(self, user_query: str) -> str:
        """
        Generate a response from the LLM based on the provided query.

        Args:
            query (str): The user's query.

        Returns:
            str: The response generated by the LLM.
        """
        retriever = RetrieverTool()
        agent = ToolCallingAgent(
            tools=[retriever],
            model=self.llm,
            verbosity_level=2
        )
        response = agent.run(user_query)

        return response
