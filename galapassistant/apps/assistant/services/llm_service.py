import os
from dotenv import load_dotenv
from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint


load_dotenv()

class AssistantLLMService:
    """
    Service class for generating responses using an LLM.
    """

    def __init__(self):
        """
        Initializes the AssistantLLMService by creating an instance of the LLM.
        """
        self.llm = HuggingFaceEndpoint(
            repo_id="HuggingFaceH4/zephyr-7b-beta",
            huggingfacehub_api_token=os.getenv("HUGGINGFACEHUB_API_TOKEN"),
            temperature=0.7,
            max_new_tokens=256,
        )

        # self.chat_model = ChatHuggingFace(llm=self.llm)

    def get_response(self, query: str) -> str:
        """
        Generate a response from the LLM based on the provided query.

        Args:
            query (str): The user's query.

        Returns:
            str: The response generated by the LLM.
        """
        return self.llm(query)
